{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation - StreamingTransformerEncoder's feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0865, -0.2938, -1.6713, -0.7352],\n",
       "         [ 0.5066, -1.7875,  2.4585, -0.8830],\n",
       "         [ 1.3333, -0.8979,  1.5627, -1.3295],\n",
       "         [ 0.4372, -0.2338,  0.8174,  0.5218],\n",
       "         [ 0.3918, -1.0793,  0.3148, -0.3560]],\n",
       "\n",
       "        [[-0.6961, -0.1982,  0.7532,  0.6678],\n",
       "         [ 1.6565,  0.4308, -0.3309, -0.0367],\n",
       "         [-1.4224, -0.2807,  1.0541,  0.3142],\n",
       "         [ 2.3469, -1.4884,  0.3607, -1.8405],\n",
       "         [-0.1464, -1.2865,  0.7448, -1.5723]]])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B T C audio data shape\n",
    "x = torch.randn(2, 5, 4)\n",
    "B, T, C = x.shape\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0865, -0.2938, -1.6713, -0.7352]],\n",
       "\n",
       "        [[-0.6961, -0.1982,  0.7532,  0.6678]]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0.]]]),\n",
       " tensor([[[0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0.]]]),\n",
       " tensor([[[0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0.]]])]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = [torch.zeros_like(x[:, :1]) for _ in range(3)]\n",
    "\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4]]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset = 0\n",
    "positions = torch.arange(T).view(1, -1, 1) + offset\n",
    "\n",
    "positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function - create_sin_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1]]])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_dim = 4\n",
    "half_dim = v_dim // 2\n",
    "adim = torch.arange(half_dim).view(1, 1, -1)\n",
    "\n",
    "adim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 1.0000e+04]]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_division = 10000 ** (adim / (half_dim-1))\n",
    "\n",
    "phase_division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 1.0000e-04],\n",
       "         [2.0000e+00, 2.0000e-04],\n",
       "         [3.0000e+00, 3.0000e-04],\n",
       "         [4.0000e+00, 4.0000e-04]]])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase = positions / (10000 ** (adim / (half_dim-1)))\n",
    "\n",
    "phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  1.0000],\n",
       "         [ 0.5403,  1.0000],\n",
       "         [-0.4161,  1.0000],\n",
       "         [-0.9900,  1.0000],\n",
       "         [-0.6536,  1.0000]]])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_cos = torch.cos(phase)\n",
    "\n",
    "phase_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00,  0.0000e+00],\n",
       "         [ 8.4147e-01,  1.0000e-04],\n",
       "         [ 9.0930e-01,  2.0000e-04],\n",
       "         [ 1.4112e-01,  3.0000e-04],\n",
       "         [-7.5680e-01,  4.0000e-04]]])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_sin = torch.sin(phase)\n",
    "\n",
    "phase_sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 5.4030e-01,  1.0000e+00,  8.4147e-01,  1.0000e-04],\n",
       "         [-4.1615e-01,  1.0000e+00,  9.0930e-01,  2.0000e-04],\n",
       "         [-9.8999e-01,  1.0000e+00,  1.4112e-01,  3.0000e-04],\n",
       "         [-6.5364e-01,  1.0000e+00, -7.5680e-01,  4.0000e-04]]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_concat = torch.concat([phase_cos, phase_sin], dim=-1)\n",
    "phase_concat_opposite = torch.concat([phase_cos, phase_sin], dim=1)\n",
    "\n",
    "phase_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sin_embedding(positions: torch.Tensor, dim: int, max_period: float = 10000):\n",
    "    assert dim % 2 == 0\n",
    "    half_dim = dim // 2\n",
    "    adim = torch.arange(half_dim, device=positions.device).view(1, 1, -1)\n",
    "    phase = positions / (max_period ** (adim / (half_dim - 1)))\n",
    "    return torch.cat([torch.cos(phase), torch.sin(phase)], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 5.4030e-01,  1.0000e+00,  8.4147e-01,  1.0000e-04],\n",
       "         [-4.1615e-01,  1.0000e+00,  9.0930e-01,  2.0000e-04],\n",
       "         [-9.8999e-01,  1.0000e+00,  1.4112e-01,  3.0000e-04],\n",
       "         [-6.5364e-01,  1.0000e+00, -7.5680e-01,  4.0000e-04]]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emb = create_sin_embedding(positions, dim=C, max_period=10000)\n",
    "\n",
    "pos_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation - StreamingTransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_queries_pos = torch.arange(2, 2 + 4, device=x.device).view(-1, 1)\n",
    "\n",
    "v_queries_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_keys_pos = torch.arange(2 + 4, device=x.device).view(1, -1)\n",
    "\n",
    "v_keys_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class - StreamingTransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingTransformerEncoderLayer(nn.TransformerEncoderLayer):\n",
    "    \"\"\"Create time embedding for the given position, target dimension `dim`\"\"\"\n",
    "    def forward(self, x: torch.Tensor, x_past: torch.Tensor, past_context: int):\n",
    "        if self.norm_first:\n",
    "            sa_input = self.norm1(x)\n",
    "            x = x + self._sa_block(sa_input, x_past, past_context)\n",
    "            x = x + self._ff_block(self.norm2(x))\n",
    "        else:\n",
    "            sa_input = x\n",
    "            x = self.norm1(x + self._sa_block(sa_input, x_past, past_context))\n",
    "            x = self.norm2(x + self._ff_block(x))\n",
    "        return x, sa_input\n",
    "    \n",
    "    def _sa_block(self, x: torch.Tensor, x_past: torch.Tensor, past_context: int):\n",
    "        _, T, _ = x.shape\n",
    "        _, H, _ = x_past.shape\n",
    "        queries = x\n",
    "        queries_pos = torch.arange(H, H + T, device=x.device).view(-1, 1)\n",
    "        keys = torch.cat([x_past, x], dim = 1)\n",
    "        keys_pos = torch.arange(H + T, device=x.device).view(1, -1)\n",
    "        values = keys\n",
    "\n",
    "        delta = queries_pos - keys_pos\n",
    "        valid_access = (delta >= 0) & (delta <= past_context)\n",
    "\n",
    "        x = self.self_attn(queries, keys, values, attn_mask=~valid_access, need_weights=False)[0]\n",
    "\n",
    "        return self.dropout1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class - StreamingTransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingTransformerEncoder(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            dim, \n",
    "            hidden_scale: int = 4,\n",
    "            num_heads: int = 8, \n",
    "            num_layers: int = 5, \n",
    "            max_period: int = 10000,\n",
    "            past_context: int = 1000,\n",
    "            gelu: bool = True,\n",
    "            norm_in: bool = True, \n",
    "            dropout: float = 0., \n",
    "            **kwargs\n",
    "            ):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0\n",
    "        hidden_dim = dim * hidden_scale\n",
    "\n",
    "        self.max_period = max_period\n",
    "        self.past_context= past_context\n",
    "        activation: tp.Any = F.gelu if gelu else F.relu\n",
    "\n",
    "        self.norm_in: nn.Module\n",
    "        if norm_in:\n",
    "            self.norm_in = nn.LayerNorm(dim)\n",
    "        else:\n",
    "            self.norm_in = nn.Identity()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for idx in range(num_layers):\n",
    "            self.layers.append(\n",
    "                StreamingTransformerEncoderLayer(\n",
    "                    dim, \n",
    "                    num_heads, \n",
    "                    hidden_dim, \n",
    "                    activation=activation, \n",
    "                    batch_first=True, \n",
    "                    dropout=dropout,\n",
    "                    **kwargs\n",
    "                    )\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            x: torch.Tensor, \n",
    "            states: tp.Optional[tp.List[torch.Tensor]] = None, \n",
    "            offset: tp.Union[int, torch.Tensor] = 0\n",
    "            ):\n",
    "        B, C, T = x.shape\n",
    "        positions = torch.arange(T, device=x.device).view(1, -1, 1) + offset\n",
    "        pos_emb = create_sin_embedding(positions, C, self.max_period)\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm_in(x)\n",
    "        x += pos_emb\n",
    "\n",
    "        if states is None:\n",
    "            states = [torch.zeros_like(x[:, :1]) for _ in range(len(self.layers) + 1)]\n",
    "        new_states: tp.List[torch.Tensor] = []\n",
    "        for state, layer in zip(states, self.layers):\n",
    "            x, new_layer = layer(x, state, self.past_context)\n",
    "            new_layer = torch.concat([state, new_layer], dim=1)\n",
    "            new_states.append(new_layer[:, -self.past_context:, :])\n",
    "        return x, new_states, offset + T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulated_audio_data:\n",
      "torch.Size([2, 16, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3661,  0.0818, -0.8510,  1.3325, -0.5567,  1.2054,  0.1599,\n",
       "           1.2376,  1.3392, -0.5552],\n",
       "         [-0.6186, -1.8180,  0.6838,  0.8326, -1.7848, -0.0643,  0.2513,\n",
       "          -0.8455,  0.3437, -0.2087],\n",
       "         [ 0.6285, -0.7177,  0.4643, -1.7050, -0.5364, -2.0309, -0.4000,\n",
       "           0.0221,  0.8664,  1.0746],\n",
       "         [-0.3609,  0.6172,  1.0386,  2.1425,  1.9318, -0.6743,  0.4873,\n",
       "           0.8535,  0.8368,  0.0124],\n",
       "         [-0.5369,  1.0483, -0.6455, -1.5342, -0.3790,  0.2303,  0.4899,\n",
       "           0.8170, -0.3221, -0.2212],\n",
       "         [-1.4927,  0.2404, -1.8879,  0.7581, -0.3032, -1.6557, -0.9824,\n",
       "           1.7419, -0.1908,  0.4613],\n",
       "         [-0.4685, -0.2954, -0.3005,  0.7489,  0.0460, -0.6783, -0.5357,\n",
       "          -1.6337, -0.1599, -0.2351],\n",
       "         [-0.3424,  1.2997, -0.9775, -1.3538, -0.5587,  0.4933,  1.5763,\n",
       "          -0.9482, -1.4368, -0.7848],\n",
       "         [-0.2884,  1.1783, -0.0507,  0.6311, -3.2857, -0.7116, -0.7674,\n",
       "           0.5432,  0.3099,  0.4940],\n",
       "         [ 2.2092, -0.9824,  0.4956,  2.0926, -1.1884, -0.5022,  0.3537,\n",
       "          -0.1510,  0.8278, -0.2647],\n",
       "         [-0.3035, -1.1683,  1.2015, -0.4572,  0.8080,  2.2902,  0.6921,\n",
       "          -0.3178,  0.9940, -0.1635],\n",
       "         [-0.8198,  0.1082,  0.1014, -1.2184,  0.4542, -0.9995, -0.1840,\n",
       "           0.5490, -0.3038,  0.7003],\n",
       "         [ 0.8450,  1.5382, -1.0012, -0.6458,  2.0060, -0.0141,  0.8080,\n",
       "           0.5200,  1.4740, -1.5371],\n",
       "         [-0.0541,  0.0273,  0.3887,  0.5237,  1.3076,  0.2885, -1.3047,\n",
       "          -0.3037,  0.3991,  0.9242],\n",
       "         [-0.6749,  1.3070, -0.2465,  1.1379,  0.9121,  0.5692,  1.6357,\n",
       "          -1.1333,  0.5160, -0.0490],\n",
       "         [-0.7883, -0.6760, -1.7679,  0.2256, -0.1335, -2.3476,  2.3565,\n",
       "           0.5078, -0.7478,  0.2920]],\n",
       "\n",
       "        [[ 0.8543, -0.1797, -1.4881,  0.5005, -0.9746,  0.1169,  0.9088,\n",
       "          -0.2273,  0.3248,  0.2281],\n",
       "         [ 2.1317, -0.0927, -0.4566, -1.0742,  1.0042,  0.9875, -0.4928,\n",
       "           1.5304, -2.0588, -1.2484],\n",
       "         [ 1.6607,  2.8145,  0.6353,  1.1899, -0.9254,  1.6372,  2.3065,\n",
       "           0.5529, -0.1992,  0.5712],\n",
       "         [ 0.5637, -1.0517,  1.0302,  0.4696, -1.7391, -0.2885,  0.9325,\n",
       "          -0.9523, -0.2435, -0.7131],\n",
       "         [ 2.5859,  0.7261, -2.1635, -1.1595,  0.8360, -1.1583, -0.3285,\n",
       "          -0.0574, -2.0501, -1.4454],\n",
       "         [ 0.7704, -1.2258,  0.5592,  0.7207, -0.0362,  1.7655,  0.5867,\n",
       "           0.8203,  0.1119, -0.0245],\n",
       "         [ 0.0458, -0.1990, -0.1257, -0.8347,  0.3125, -1.4618,  1.2278,\n",
       "           1.2632,  0.4352,  1.0276],\n",
       "         [-0.7835,  1.6405, -0.6084, -0.2131,  0.3016, -0.1129, -0.4149,\n",
       "          -0.0348, -0.8545,  0.4581],\n",
       "         [ 1.6884, -0.0537, -0.8465, -1.0541, -1.0203,  0.0692,  0.3564,\n",
       "           0.3026,  1.4703, -0.6442],\n",
       "         [ 1.5546, -1.2553,  0.6514, -1.2299,  1.7420, -0.7090,  0.6125,\n",
       "           0.9210, -0.4937, -1.5310],\n",
       "         [-1.0414, -0.3327,  0.6985, -1.1890, -1.5187, -1.7901,  1.1305,\n",
       "          -0.3738, -1.4325, -2.0819],\n",
       "         [-0.8401, -0.7112, -0.3005,  0.9811, -0.7695, -0.6204, -1.3366,\n",
       "           0.5292, -0.1831,  0.9956],\n",
       "         [-0.9061,  0.1152, -1.4847,  0.7101,  0.6887,  0.5649,  0.2019,\n",
       "          -0.6379,  0.8747, -0.0037],\n",
       "         [-0.7658,  0.7765, -1.6582, -0.5452, -0.2819, -0.6150, -0.4733,\n",
       "          -0.2388, -0.0795,  0.9207],\n",
       "         [-1.0434,  1.1154,  1.1035, -0.8824, -1.3092, -1.3586, -0.2908,\n",
       "          -0.6431,  0.2328, -0.1269],\n",
       "         [ 1.2915,  1.1958,  0.5792, -0.2245, -0.8679, -0.4036,  0.3853,\n",
       "          -0.4868, -0.3713,  0.0080]]])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = StreamingTransformerEncoder(dim=16, num_heads=4, num_layers=3)\n",
    "\n",
    "simulated_audio_data = torch.randn(2, 16, 10) # the data is in ordered B, C, T form\n",
    "\n",
    "print(f\"simulated_audio_data:\\n{simulated_audio_data.shape}\")\n",
    "simulated_audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "torch.Size([2, 16, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.7096e+00,  2.2952e-01, -1.1216e+00,  6.7533e-01, -4.3854e-01,\n",
       "           1.3946e+00,  7.4558e-01,  1.7598e+00,  1.3663e+00, -1.6166e+00],\n",
       "         [ 1.4923e-01, -1.2565e+00,  8.1344e-01,  4.6468e-01, -1.7833e+00,\n",
       "          -6.0504e-01, -8.4396e-01, -1.9806e+00, -1.2982e+00, -1.2926e+00],\n",
       "         [ 1.0823e+00, -2.1431e-01,  1.1000e+00, -2.3361e-01,  6.6281e-02,\n",
       "          -4.8274e-01, -4.5998e-01,  1.0350e-01,  9.9526e-01,  1.2699e+00],\n",
       "         [-4.1495e-01,  1.0108e+00,  1.5395e+00,  1.3699e+00,  1.4542e+00,\n",
       "           3.6927e-01,  7.7336e-01,  3.8977e-01,  3.4878e-01,  7.5649e-01],\n",
       "         [-6.1157e-01,  1.0671e+00, -6.6021e-01, -1.5160e+00, -5.2035e-02,\n",
       "           4.9523e-01,  4.7828e-01,  9.6017e-01, -9.3844e-01, -4.0545e-02],\n",
       "         [-1.4059e+00,  2.3096e-02, -1.7226e+00,  4.5063e-01, -2.4989e-02,\n",
       "          -8.2499e-01, -1.6819e+00,  1.4045e+00, -6.0121e-01,  8.9652e-01],\n",
       "         [ 3.8415e-01, -1.2221e-01,  4.1802e-01,  1.0778e+00,  2.9510e-01,\n",
       "          -1.8279e-01, -6.2965e-01, -9.6433e-01,  1.9171e-01,  3.2166e-02],\n",
       "         [ 1.2144e-01,  1.4359e+00, -1.0961e-01, -5.8058e-01,  1.1644e-01,\n",
       "           1.0002e+00,  1.6943e+00, -1.0019e+00, -1.5376e+00, -5.1063e-01],\n",
       "         [-7.4518e-02,  1.2517e+00,  6.1681e-01, -1.5139e-01, -2.4823e+00,\n",
       "          -1.1871e+00, -1.5539e+00,  6.4898e-01,  7.1673e-01,  2.4656e-01],\n",
       "         [ 8.2816e-01, -1.7246e+00,  7.0256e-01,  1.9738e+00, -5.6054e-01,\n",
       "          -1.9860e-01,  3.0765e-02, -8.5720e-01,  5.1750e-01, -7.8906e-01],\n",
       "         [-4.2255e-01, -1.4775e+00,  8.7952e-01, -8.7640e-01,  1.1369e+00,\n",
       "           1.9500e+00,  6.0051e-01,  1.9358e-01,  1.1893e+00,  4.1522e-01],\n",
       "         [-9.2922e-01, -7.5080e-01, -8.6295e-02, -1.5115e+00,  3.3901e-01,\n",
       "          -3.3621e-01, -2.3683e-01,  4.6212e-01, -5.4052e-01,  8.7594e-01],\n",
       "         [ 6.3959e-01,  8.0617e-01, -7.7064e-01, -1.2349e+00,  1.0615e+00,\n",
       "           1.3706e-01,  3.6947e-01,  2.6173e-01,  1.2088e+00, -1.7713e+00],\n",
       "         [ 1.9807e-01,  5.5860e-01,  5.5168e-01,  7.3581e-01,  1.0778e+00,\n",
       "           6.1885e-01, -1.4348e+00,  3.6350e-01,  7.2452e-01,  1.8908e+00],\n",
       "         [-1.2970e+00,  4.4321e-01, -6.4353e-02, -4.6710e-02,  2.2228e-01,\n",
       "           2.0824e-01,  7.1269e-01, -1.5281e+00, -6.8497e-01, -3.5738e-01],\n",
       "         [-9.5677e-01, -1.2801e+00, -2.0863e+00, -5.9693e-01, -4.2784e-01,\n",
       "          -2.3559e+00,  1.4360e+00, -2.1552e-01, -1.6580e+00, -5.5834e-03]],\n",
       "\n",
       "        [[ 9.1624e-01, -6.1566e-01, -1.3255e+00,  5.4644e-01, -1.6851e-01,\n",
       "           1.7460e+00,  2.0880e+00,  1.3654e+00,  6.9036e-01,  4.1309e-02],\n",
       "         [ 1.9922e+00,  1.0046e+00,  6.2267e-01, -1.2026e+00,  6.6157e-01,\n",
       "           5.2277e-01, -1.2311e+00,  9.5670e-01, -2.6007e+00, -2.4778e+00],\n",
       "         [ 1.2406e+00,  1.4794e+00,  9.6541e-01,  1.6898e+00, -5.2371e-02,\n",
       "           1.6008e+00,  1.8847e+00,  9.6238e-01,  6.4368e-01,  8.4769e-01],\n",
       "         [-6.1068e-03, -3.8907e-01,  1.5047e+00,  9.1693e-01, -1.1168e+00,\n",
       "          -8.3200e-01, -9.4290e-02, -1.6044e+00, -3.9192e-01,  1.4689e-01],\n",
       "         [ 1.3617e+00,  1.1017e+00, -1.3664e+00, -4.9169e-02,  1.5513e+00,\n",
       "           2.6923e-01, -3.9495e-01,  4.1687e-01, -8.8724e-01, -8.1382e-02],\n",
       "         [-3.2520e-01, -1.3934e+00,  2.5671e-01,  8.9223e-01, -3.6913e-01,\n",
       "           1.1919e+00, -4.2574e-01,  6.3880e-02,  2.4246e-01,  2.1364e-01],\n",
       "         [-5.8323e-01, -7.7905e-01,  1.2674e-01, -6.3018e-01,  5.5186e-01,\n",
       "          -7.7742e-01,  6.4932e-01,  1.2400e+00,  8.9511e-01,  1.0473e+00],\n",
       "         [-5.2266e-01,  1.5992e+00,  4.4896e-01,  4.7321e-01,  1.0983e+00,\n",
       "           4.2645e-01, -1.7885e-01,  2.4508e-01,  2.1014e-01,  1.4062e+00],\n",
       "         [ 4.9196e-01, -7.6345e-01, -6.1123e-01, -1.5231e+00, -1.3227e+00,\n",
       "          -1.1270e+00, -4.6933e-01,  7.7107e-01,  2.1509e+00, -3.1099e-01],\n",
       "         [-5.2850e-02, -1.5129e+00,  1.1654e+00, -1.0056e+00,  1.6041e+00,\n",
       "          -6.8397e-01,  5.4890e-01,  7.4130e-01,  2.4311e-02, -1.3379e+00],\n",
       "         [-1.5484e+00, -6.3847e-01, -8.1587e-02, -6.9437e-01, -9.5136e-01,\n",
       "          -8.2830e-01,  9.6431e-01, -7.4409e-01, -8.0164e-01, -1.0940e+00],\n",
       "         [-1.7034e+00, -1.1007e+00, -4.2242e-01,  1.1412e+00, -4.6196e-01,\n",
       "          -3.6979e-01, -1.3893e+00, -2.5790e-01, -2.3276e-01,  1.0785e+00],\n",
       "         [ 3.7578e-01,  8.7705e-01, -4.7144e-01,  1.5494e+00,  1.5238e+00,\n",
       "           1.4594e+00,  4.8028e-01,  4.4333e-02,  6.4218e-01,  2.6678e-02],\n",
       "         [-5.6766e-01, -1.9817e-03, -2.1743e+00, -6.7671e-01, -4.3348e-01,\n",
       "          -6.4386e-01, -9.3544e-01, -1.0896e+00,  4.6169e-01,  1.2161e+00],\n",
       "         [-1.0348e+00,  7.2537e-01,  1.2787e+00, -9.8400e-01, -9.0917e-01,\n",
       "          -1.2317e+00, -1.0359e+00, -1.2803e+00, -4.8333e-01, -4.1085e-01],\n",
       "         [-3.4164e-02,  4.0727e-01,  8.3609e-02, -4.4356e-01, -1.2054e+00,\n",
       "          -7.2245e-01, -4.6062e-01, -1.8308e+00, -5.6320e-01, -3.1132e-01]]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, new_states, new_offset = model(simulated_audio_data)\n",
    "output = output.permute(0, 2, 1)\n",
    "\n",
    "print(f\"output:\\n{output.shape}\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "new_states:\n",
      "3\n",
      "\n",
      "\n",
      "new_offset:\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n\\nnew_states:\\n{len(new_states)}\")\n",
    "print(f\"\\n\\nnew_offset:\\n{new_offset}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
